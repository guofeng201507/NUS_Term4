{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvLP7JaZmAse"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "PNkx5WRymEBy",
    "outputId": "b4a432c9-63b2-4d16-a155-2253a8c7c713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\r",
      "\u001b[K     |▉                               | 10kB 17.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 61kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 71kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 81kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 92kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 225kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 235kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 245kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 256kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 266kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 276kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 286kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 296kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 307kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 317kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 327kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 337kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 348kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 358kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 368kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Nx4zEe5-SXWF",
    "outputId": "40a7e874-0253-407e-9f04-7d46dacb4c39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "import tensorflow as tf;\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6a9kxViHGv33"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.preprocessing.text import Tokenizer, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "kfOWnmsBRViz",
    "outputId": "e23bb75a-d22e-490f-aa1b-c33eb03679db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot_keras_history in /usr/local/lib/python3.6/dist-packages (1.1.23)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from plot_keras_history) (1.0.5)\n",
      "Requirement already satisfied: sanitize-ml-labels in /usr/local/lib/python3.6/dist-packages (from plot_keras_history) (1.0.12)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from plot_keras_history) (3.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from plot_keras_history) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->plot_keras_history) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->plot_keras_history) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->plot_keras_history) (2.8.1)\n",
      "Requirement already satisfied: compress-json in /usr/local/lib/python3.6/dist-packages (from sanitize-ml-labels->plot_keras_history) (1.0.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot_keras_history) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot_keras_history) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->plot_keras_history) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJGUagKRHYvg"
   },
   "outputs": [],
   "source": [
    "fullines= pd.read_csv('kopitiam.csv', header = 0)\n",
    "\n",
    "\n",
    "\n",
    "#Any pairwise and sequence data can be processed\n",
    "#Not only for translation OR Everything is \"translation\"\n",
    "#For example: \n",
    "  #Question , Answer pairs\n",
    "  #Image , caption pairs\n",
    "  #song , lyric pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBo654coK2g-"
   },
   "outputs": [],
   "source": [
    "#Data Preprocessing \n",
    "#Will differ according to the nature of the data. \n",
    "#This step is important!!! and time consuming!!!!\n",
    "\n",
    "#Lowercase\n",
    "fullines.SeqA=fullines.SeqA.apply(lambda x: x.lower())\n",
    "fullines.SeqB=fullines.SeqB.apply(lambda x: x.lower())\n",
    "\n",
    "#remove digits\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "fullines.SeqA=fullines.SeqA.apply(lambda x: x.translate(remove_digits))\n",
    "fullines.SeqB=fullines.SeqB.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "#Special for Decoder SeqB\n",
    "fullines.SeqB = fullines.SeqB.apply(lambda x : '$START '+ x + ' END$')\n",
    "\n",
    "\n",
    "\n",
    "lines, testlines =  train_test_split(fullines, train_size = 0.8,random_state=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqA</th>\n",
       "      <th>SeqB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kopi o</td>\n",
       "      <td>$START black coffee with sugar END$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kopi</td>\n",
       "      <td>$START black coffee with condensed milk END$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kopi c</td>\n",
       "      <td>$START black coffee with evaporated milk END$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kopi kosong</td>\n",
       "      <td>$START black coffee without sugar or milk END$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kopi gah dai</td>\n",
       "      <td>$START black coffee with extra condensed milk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SeqA                                               SeqB\n",
       "0        kopi o                $START black coffee with sugar END$\n",
       "1          kopi       $START black coffee with condensed milk END$\n",
       "2        kopi c      $START black coffee with evaporated milk END$\n",
       "3   kopi kosong     $START black coffee without sugar or milk END$\n",
       "4  kopi gah dai  $START black coffee with extra condensed milk ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "XMtB_nxdRcti",
    "outputId": "64d00b4e-3318-4d18-83e1-29e66fed18b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 7], [2, 4], [1, 6], [1, 7, 10, 3], [1, 7], [2, 29], [2, 6], [2, 6], [1, 4, 5]]\n",
      "vocabubary size: 63\n",
      "max length text: 5\n"
     ]
    }
   ],
   "source": [
    "#tokenize and index the sequence A\n",
    "\n",
    "tokenizer_A = Tokenizer()\n",
    "tokenizer_A.fit_on_texts(lines.SeqA)\n",
    "\n",
    "seqA = tokenizer_A.texts_to_sequences(lines.SeqA)\n",
    "print(seqA[0:10])\n",
    "word_index_A = tokenizer_A.word_index\n",
    "\n",
    "vocab_size_A = len(word_index_A) + 1  # Adding 1 because of reserved 0 index by Tokenizer\n",
    "maxlen_A = max(len(x) for x in seqA) # longest text in train set\n",
    "print('vocabubary size:',vocab_size_A)\n",
    "print('max length text:',maxlen_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "kT2BENUbSbOc",
    "outputId": "0f24131b-ef54-4184-e0f1-c06994c59a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 12, 5, 15, 6, 22, 4, 2], [1, 23, 5, 3, 9, 4, 2], [1, 7, 3, 6, 28, 2], [1, 12, 5, 3, 13, 4, 2], [1, 10, 5, 3, 9, 4, 8, 11, 5, 14, 8, 11, 6, 2], [1, 10, 5, 3, 9, 4, 8, 6, 8, 11, 5, 14, 2], [1, 7, 3, 13, 4, 2], [1, 10, 7, 3, 13, 4, 8, 6, 2], [1, 7, 3, 13, 4, 8, 6, 40, 17, 9, 4, 2], [1, 5, 15, 6, 22, 4, 2]]\n",
      "{'$start': 1, 'end$': 2, 'with': 3, 'milk': 4, 'coffee': 5, 'sugar': 6, 'tea': 7, 'and': 8, 'condensed': 9, 'hot': 10, 'more': 11, 'black': 12, 'evaporated': 13, 'powder': 14, 'without': 15, 'lesser': 16, 'of': 17, 'less': 18, 'iced': 19, 'water': 20, 'milo': 21, 'or': 22, 'strong': 23, 'but': 24, 'the': 25, 'no': 26, 'added': 27, 'only': 28, 'brew': 29, 'a': 30, 'to': 31, 'version': 32, 'initial': 33, 'ice': 34, 'weaker': 35, 'horlicks': 36, 'pulled': 37, 'is': 38, 'ginger': 39, 'instead': 40, 'they': 41, 'add': 42, 'iced\\xa0tea': 43, 'heaviest': 44, 'purest': 45, 'at': 46, 'all': 47, 'simply': 48, 'any': 49, 'kind': 50, 'weak': 51, 'thicker': 52, 'robust': 53, 'for': 54, 'heavier': 55, 'taste': 56, 'malay': 57, 'stout': 58, 'served': 59, 'teabag': 60, 'includes': 61, 'bean': 62, 'undissolved': 63, 'lemon': 64, 'chinese': 65, 'extra': 66, 'frothy': 67, 'sweet': 68, 'thinner': 69, 'dilute': 70, 'beverage': 71, 'described': 72, 'above': 73, 'cofee': 74, 'cappuccino': 75, 'concentration': 76, 'guinness': 77, 'chrysanthemum': 78, 'soya': 79, 'mixed': 80, 'grass': 81, 'jelly': 82, '‘pulled’': 83, 'specialty': 84, 'plus': 85, 'very': 86, 'lager': 87, 'guiness': 88, 'as': 89, 'topping': 90, 'home': 91, 'brewed': 92, 'chin': 93, 'chow': 94, 'soy': 95, 'pepsi': 96, 'cola': 97, 'kickapoo': 98, 'in': 99, 'bags': 100, 'thin': 101, 'takeaway': 102, 'scoop': 103, 'on': 104, 'top': 105, 'rose': 106, 'syrup': 107, 'drink': 108}\n",
      "vocabubary size: 109\n",
      "max length text: 17\n"
     ]
    }
   ],
   "source": [
    "#tokenize and index the sequence B\n",
    "\n",
    "tokenizer_B = Tokenizer(filters='!\"#%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',)\n",
    "tokenizer_B.fit_on_texts(lines.SeqB)\n",
    "\n",
    "seqB = tokenizer_B.texts_to_sequences(lines.SeqB)\n",
    "print(seqB[0:10])\n",
    "word_index_B = tokenizer_B.word_index\n",
    "\n",
    "print(word_index_B)\n",
    "\n",
    "vocab_size_B = len(word_index_B) + 1  # Adding 1 because of reserved 0 index by Tokenizer\n",
    "maxlen_B = max(len(x) for x in seqB) # longest text in train set\n",
    "print('vocabubary size:',vocab_size_B)\n",
    "print('max length text:',maxlen_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WofBOOxCSzFh"
   },
   "outputs": [],
   "source": [
    "# seqA_vec -> encoder -> seqB_vec -> decoder -> seqB_one-hot-matrix (ahead by one timestep)\n",
    "\n",
    "# First define the vectors' shape with all 0s as value\n",
    "\n",
    "encoder_input_data = np.zeros((len(seqA), maxlen_A, vocab_size_A), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(seqA), maxlen_B, vocab_size_B), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(seqA), maxlen_B, vocab_size_B),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D7T4v9DWxfu"
   },
   "outputs": [],
   "source": [
    "#Then populate the word_index as the value\n",
    "for i, (input_text, target_text) in enumerate(zip(seqA, seqB)):\n",
    "    for t, word_id in enumerate(input_text):\n",
    "        encoder_input_data[i, t, word_id] = 1.\n",
    "#    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, word_id in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, word_id] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, word_id] = 1.0\n",
    "    #decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    #decoder_target_data[i, t:, target_token_index[' ']] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "mLwuoSaOaVDK",
    "outputId": "be4be0f3-b7d2-4c42-c79c-b8cb942e4cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#check the index for the first pair \n",
    "print(\"encoder:\")\n",
    "print(encoder_input_data[0])\n",
    "print(decoder_input_data[0])\n",
    "print(\"target:\")\n",
    "print(decoder_target_data[0,0])\n",
    "print(decoder_target_data[0,1])\n",
    "print(decoder_target_data[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "iMfJYAVlbLLG",
    "outputId": "6f6c6b1a-612e-4cc1-9c68-e4859a07c9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 63)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 109)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 32), (None,  12288       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 32), ( 18176       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 109)    3597        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 34,061\n",
      "Trainable params: 34,061\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build Seq2Seq model using LSTM\n",
    "\n",
    "embedding_size = 64\n",
    "hidden_dim = 32\n",
    "\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "#Encoder Part: {encoder_input -> lstm} -> encoder_states\n",
    "encoder_inputs = Input(shape=(None, vocab_size_A))\n",
    "encoder = LSTM(hidden_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Decoder Part:{[decoder_input , encoder_states] ----> lstm} --> last_dense_layer\n",
    "decoder_inputs = Input(shape=(None, vocab_size_B))\n",
    "decoder_lstm = LSTM(hidden_dim, return_sequences=True, return_state=True)#define lstm\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)#link: [decoder_input,encoder_states] ----> lstm\n",
    "decoder_dense = Dense(vocab_size_B, activation='softmax')#define last_dense_layer\n",
    "decoder_outputs = decoder_dense(decoder_outputs)#link:{[decoder_input,encoder_states] ----> lstm} -> last_dense_layer\n",
    "\n",
    "#Link encoder -> decoder \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJ2Tw6fsUIC8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107 samples, validate on 27 samples\n",
      "Epoch 1/200\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 2.0471 - accuracy: 0.0363 - val_loss: 1.8619 - val_accuracy: 0.0610\n",
      "Epoch 2/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 1.9013 - accuracy: 0.0605 - val_loss: 1.6233 - val_accuracy: 0.0588\n",
      "Epoch 3/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.6745 - accuracy: 0.0588 - val_loss: 1.4668 - val_accuracy: 0.0588\n",
      "Epoch 4/200\n",
      "107/107 [==============================] - 0s 925us/step - loss: 1.5746 - accuracy: 0.0588 - val_loss: 1.4091 - val_accuracy: 0.0588\n",
      "Epoch 5/200\n",
      "107/107 [==============================] - 0s 888us/step - loss: 1.5377 - accuracy: 0.0588 - val_loss: 1.3895 - val_accuracy: 0.0588\n",
      "Epoch 6/200\n",
      "107/107 [==============================] - 0s 794us/step - loss: 1.5198 - accuracy: 0.0588 - val_loss: 1.3818 - val_accuracy: 0.0588\n",
      "Epoch 7/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.5071 - accuracy: 0.0588 - val_loss: 1.3743 - val_accuracy: 0.0588\n",
      "Epoch 8/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.4953 - accuracy: 0.0588 - val_loss: 1.3660 - val_accuracy: 0.0588\n",
      "Epoch 9/200\n",
      "107/107 [==============================] - 0s 785us/step - loss: 1.4818 - accuracy: 0.0616 - val_loss: 1.3549 - val_accuracy: 0.0915\n",
      "Epoch 10/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.4666 - accuracy: 0.0885 - val_loss: 1.3436 - val_accuracy: 0.0980\n",
      "Epoch 11/200\n",
      "107/107 [==============================] - 0s 794us/step - loss: 1.4509 - accuracy: 0.0913 - val_loss: 1.3352 - val_accuracy: 0.1046\n",
      "Epoch 12/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 1.4347 - accuracy: 0.1006 - val_loss: 1.3214 - val_accuracy: 0.1111\n",
      "Epoch 13/200\n",
      "107/107 [==============================] - 0s 794us/step - loss: 1.4205 - accuracy: 0.1017 - val_loss: 1.3097 - val_accuracy: 0.1111\n",
      "Epoch 14/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.4043 - accuracy: 0.1017 - val_loss: 1.2968 - val_accuracy: 0.1111\n",
      "Epoch 15/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 1.3850 - accuracy: 0.1089 - val_loss: 1.2794 - val_accuracy: 0.1220\n",
      "Epoch 16/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.3640 - accuracy: 0.1100 - val_loss: 1.2643 - val_accuracy: 0.1307\n",
      "Epoch 17/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 1.3464 - accuracy: 0.1187 - val_loss: 1.2475 - val_accuracy: 0.1285\n",
      "Epoch 18/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.3295 - accuracy: 0.1160 - val_loss: 1.2381 - val_accuracy: 0.1351\n",
      "Epoch 19/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.3139 - accuracy: 0.1226 - val_loss: 1.2269 - val_accuracy: 0.1394\n",
      "Epoch 20/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.2974 - accuracy: 0.1220 - val_loss: 1.2149 - val_accuracy: 0.1394\n",
      "Epoch 21/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.2844 - accuracy: 0.1253 - val_loss: 1.2095 - val_accuracy: 0.1394\n",
      "Epoch 22/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.2679 - accuracy: 0.1297 - val_loss: 1.2088 - val_accuracy: 0.1373\n",
      "Epoch 23/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 1.2544 - accuracy: 0.1352 - val_loss: 1.1888 - val_accuracy: 0.1438\n",
      "Epoch 24/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.2404 - accuracy: 0.1391 - val_loss: 1.1814 - val_accuracy: 0.1438\n",
      "Epoch 25/200\n",
      "107/107 [==============================] - 0s 831us/step - loss: 1.2271 - accuracy: 0.1391 - val_loss: 1.1758 - val_accuracy: 0.1438\n",
      "Epoch 26/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.2133 - accuracy: 0.1402 - val_loss: 1.1686 - val_accuracy: 0.1460\n",
      "Epoch 27/200\n",
      "107/107 [==============================] - 0s 907us/step - loss: 1.2004 - accuracy: 0.1468 - val_loss: 1.1718 - val_accuracy: 0.1416\n",
      "Epoch 28/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.1879 - accuracy: 0.1479 - val_loss: 1.1525 - val_accuracy: 0.1481\n",
      "Epoch 29/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.1752 - accuracy: 0.1495 - val_loss: 1.1432 - val_accuracy: 0.1547\n",
      "Epoch 30/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.1615 - accuracy: 0.1539 - val_loss: 1.1457 - val_accuracy: 0.1678\n",
      "Epoch 31/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 1.1507 - accuracy: 0.1545 - val_loss: 1.1435 - val_accuracy: 0.1569\n",
      "Epoch 32/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.1363 - accuracy: 0.1655 - val_loss: 1.1241 - val_accuracy: 0.1547\n",
      "Epoch 33/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.1262 - accuracy: 0.1616 - val_loss: 1.1189 - val_accuracy: 0.1547\n",
      "Epoch 34/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 1.1147 - accuracy: 0.1622 - val_loss: 1.1198 - val_accuracy: 0.1743\n",
      "Epoch 35/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.1026 - accuracy: 0.1721 - val_loss: 1.1120 - val_accuracy: 0.1699\n",
      "Epoch 36/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.0905 - accuracy: 0.1688 - val_loss: 1.1194 - val_accuracy: 0.1765\n",
      "Epoch 37/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 1.0798 - accuracy: 0.1770 - val_loss: 1.1023 - val_accuracy: 0.1786\n",
      "Epoch 38/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 1.0700 - accuracy: 0.1754 - val_loss: 1.0997 - val_accuracy: 0.1765\n",
      "Epoch 39/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 1.0578 - accuracy: 0.1787 - val_loss: 1.0931 - val_accuracy: 0.1743\n",
      "Epoch 40/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.0484 - accuracy: 0.1814 - val_loss: 1.0922 - val_accuracy: 0.1699\n",
      "Epoch 41/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.0363 - accuracy: 0.1809 - val_loss: 1.0856 - val_accuracy: 0.1765\n",
      "Epoch 42/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 1.0261 - accuracy: 0.1842 - val_loss: 1.0958 - val_accuracy: 0.1830\n",
      "Epoch 43/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 1.0152 - accuracy: 0.1869 - val_loss: 1.0757 - val_accuracy: 0.1743\n",
      "Epoch 44/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 1.0046 - accuracy: 0.1891 - val_loss: 1.0738 - val_accuracy: 0.1808\n",
      "Epoch 45/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.9936 - accuracy: 0.1908 - val_loss: 1.0626 - val_accuracy: 0.1808\n",
      "Epoch 46/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.9858 - accuracy: 0.1935 - val_loss: 1.0658 - val_accuracy: 0.1852\n",
      "Epoch 47/200\n",
      "107/107 [==============================] - 0s 878us/step - loss: 0.9724 - accuracy: 0.1963 - val_loss: 1.0578 - val_accuracy: 0.1830\n",
      "Epoch 48/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.9653 - accuracy: 0.1979 - val_loss: 1.0462 - val_accuracy: 0.1852\n",
      "Epoch 49/200\n",
      "107/107 [==============================] - 0s 860us/step - loss: 0.9515 - accuracy: 0.1957 - val_loss: 1.0635 - val_accuracy: 0.1917\n",
      "Epoch 50/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.9441 - accuracy: 0.2007 - val_loss: 1.0360 - val_accuracy: 0.1830\n",
      "Epoch 51/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.9323 - accuracy: 0.2029 - val_loss: 1.0602 - val_accuracy: 0.1852\n",
      "Epoch 52/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.9260 - accuracy: 0.2029 - val_loss: 1.0309 - val_accuracy: 0.1961\n",
      "Epoch 53/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.9142 - accuracy: 0.2089 - val_loss: 1.0211 - val_accuracy: 0.2004\n",
      "Epoch 54/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.9043 - accuracy: 0.2128 - val_loss: 1.0184 - val_accuracy: 0.1961\n",
      "Epoch 55/200\n",
      "107/107 [==============================] - 0s 935us/step - loss: 0.8950 - accuracy: 0.2122 - val_loss: 1.0116 - val_accuracy: 0.1983\n",
      "Epoch 56/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.8861 - accuracy: 0.2155 - val_loss: 1.0120 - val_accuracy: 0.2070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.8749 - accuracy: 0.2150 - val_loss: 1.0099 - val_accuracy: 0.2004\n",
      "Epoch 58/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.8658 - accuracy: 0.2194 - val_loss: 1.0179 - val_accuracy: 0.2026\n",
      "Epoch 59/200\n",
      "107/107 [==============================] - 0s 888us/step - loss: 0.8578 - accuracy: 0.2226 - val_loss: 0.9951 - val_accuracy: 0.2026\n",
      "Epoch 60/200\n",
      "107/107 [==============================] - 0s 860us/step - loss: 0.8477 - accuracy: 0.2265 - val_loss: 1.0013 - val_accuracy: 0.2092\n",
      "Epoch 61/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.8373 - accuracy: 0.2287 - val_loss: 0.9887 - val_accuracy: 0.2048\n",
      "Epoch 62/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.8298 - accuracy: 0.2276 - val_loss: 0.9840 - val_accuracy: 0.2135\n",
      "Epoch 63/200\n",
      "107/107 [==============================] - 0s 851us/step - loss: 0.8200 - accuracy: 0.2309 - val_loss: 0.9854 - val_accuracy: 0.2135\n",
      "Epoch 64/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.8112 - accuracy: 0.2287 - val_loss: 0.9792 - val_accuracy: 0.2113\n",
      "Epoch 65/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.8013 - accuracy: 0.2342 - val_loss: 0.9922 - val_accuracy: 0.2070\n",
      "Epoch 66/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.7935 - accuracy: 0.2292 - val_loss: 0.9787 - val_accuracy: 0.2113\n",
      "Epoch 67/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 0.7840 - accuracy: 0.2413 - val_loss: 0.9788 - val_accuracy: 0.2135\n",
      "Epoch 68/200\n",
      "107/107 [==============================] - 0s 859us/step - loss: 0.7761 - accuracy: 0.2375 - val_loss: 0.9851 - val_accuracy: 0.2113\n",
      "Epoch 69/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.7688 - accuracy: 0.2435 - val_loss: 0.9622 - val_accuracy: 0.2179\n",
      "Epoch 70/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.7608 - accuracy: 0.2435 - val_loss: 0.9591 - val_accuracy: 0.2157\n",
      "Epoch 71/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.7497 - accuracy: 0.2474 - val_loss: 0.9930 - val_accuracy: 0.2070\n",
      "Epoch 72/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.7442 - accuracy: 0.2518 - val_loss: 0.9623 - val_accuracy: 0.2157\n",
      "Epoch 73/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.7351 - accuracy: 0.2501 - val_loss: 0.9588 - val_accuracy: 0.2157\n",
      "Epoch 74/200\n",
      "107/107 [==============================] - 0s 851us/step - loss: 0.7270 - accuracy: 0.2534 - val_loss: 0.9639 - val_accuracy: 0.2157\n",
      "Epoch 75/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.7203 - accuracy: 0.2573 - val_loss: 0.9573 - val_accuracy: 0.2135\n",
      "Epoch 76/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.7099 - accuracy: 0.2562 - val_loss: 0.9547 - val_accuracy: 0.2179\n",
      "Epoch 77/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.7048 - accuracy: 0.2639 - val_loss: 0.9485 - val_accuracy: 0.2200\n",
      "Epoch 78/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.6992 - accuracy: 0.2589 - val_loss: 0.9544 - val_accuracy: 0.2157\n",
      "Epoch 79/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.6893 - accuracy: 0.2672 - val_loss: 0.9523 - val_accuracy: 0.2179\n",
      "Epoch 80/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.6819 - accuracy: 0.2721 - val_loss: 0.9520 - val_accuracy: 0.2222\n",
      "Epoch 81/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.6758 - accuracy: 0.2710 - val_loss: 0.9449 - val_accuracy: 0.2179\n",
      "Epoch 82/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.6682 - accuracy: 0.2732 - val_loss: 0.9497 - val_accuracy: 0.2179\n",
      "Epoch 83/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.6604 - accuracy: 0.2727 - val_loss: 0.9453 - val_accuracy: 0.2200\n",
      "Epoch 84/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.6537 - accuracy: 0.2754 - val_loss: 0.9515 - val_accuracy: 0.2179\n",
      "Epoch 85/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.6486 - accuracy: 0.2771 - val_loss: 0.9360 - val_accuracy: 0.2200\n",
      "Epoch 86/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.6423 - accuracy: 0.2771 - val_loss: 0.9389 - val_accuracy: 0.2200\n",
      "Epoch 87/200\n",
      "107/107 [==============================] - 0s 812us/step - loss: 0.6333 - accuracy: 0.2787 - val_loss: 0.9366 - val_accuracy: 0.2222\n",
      "Epoch 88/200\n",
      "107/107 [==============================] - 0s 837us/step - loss: 0.6259 - accuracy: 0.2815 - val_loss: 0.9326 - val_accuracy: 0.2266\n",
      "Epoch 89/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.6229 - accuracy: 0.2848 - val_loss: 0.9290 - val_accuracy: 0.2222\n",
      "Epoch 90/200\n",
      "107/107 [==============================] - 0s 991us/step - loss: 0.6142 - accuracy: 0.2831 - val_loss: 0.9326 - val_accuracy: 0.2222\n",
      "Epoch 91/200\n",
      "107/107 [==============================] - 0s 897us/step - loss: 0.6072 - accuracy: 0.2859 - val_loss: 0.9308 - val_accuracy: 0.2200\n",
      "Epoch 92/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.6016 - accuracy: 0.2875 - val_loss: 0.9218 - val_accuracy: 0.2222\n",
      "Epoch 93/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5960 - accuracy: 0.2897 - val_loss: 0.9330 - val_accuracy: 0.2222\n",
      "Epoch 94/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5901 - accuracy: 0.2853 - val_loss: 0.9269 - val_accuracy: 0.2309\n",
      "Epoch 95/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.5851 - accuracy: 0.2908 - val_loss: 0.9280 - val_accuracy: 0.2266\n",
      "Epoch 96/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.5791 - accuracy: 0.2925 - val_loss: 0.9439 - val_accuracy: 0.2200\n",
      "Epoch 97/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.5728 - accuracy: 0.2947 - val_loss: 0.9229 - val_accuracy: 0.2288\n",
      "Epoch 98/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5672 - accuracy: 0.2941 - val_loss: 0.9157 - val_accuracy: 0.2331\n",
      "Epoch 99/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5609 - accuracy: 0.3013 - val_loss: 0.9172 - val_accuracy: 0.2331\n",
      "Epoch 100/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5566 - accuracy: 0.3018 - val_loss: 0.9181 - val_accuracy: 0.2266\n",
      "Epoch 101/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5511 - accuracy: 0.2985 - val_loss: 0.9139 - val_accuracy: 0.2331\n",
      "Epoch 102/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.5459 - accuracy: 0.2974 - val_loss: 0.9223 - val_accuracy: 0.2288\n",
      "Epoch 103/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.5394 - accuracy: 0.3013 - val_loss: 0.9135 - val_accuracy: 0.2309\n",
      "Epoch 104/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.5323 - accuracy: 0.3057 - val_loss: 0.9228 - val_accuracy: 0.2244\n",
      "Epoch 105/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.5304 - accuracy: 0.3024 - val_loss: 0.9157 - val_accuracy: 0.2309\n",
      "Epoch 106/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.5221 - accuracy: 0.3057 - val_loss: 0.9153 - val_accuracy: 0.2353\n",
      "Epoch 107/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.5178 - accuracy: 0.3051 - val_loss: 0.9280 - val_accuracy: 0.2331\n",
      "Epoch 108/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.5155 - accuracy: 0.3007 - val_loss: 0.9138 - val_accuracy: 0.2288\n",
      "Epoch 109/200\n",
      "107/107 [==============================] - 0s 809us/step - loss: 0.5071 - accuracy: 0.3090 - val_loss: 0.9124 - val_accuracy: 0.2309\n",
      "Epoch 110/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.5037 - accuracy: 0.3068 - val_loss: 0.9190 - val_accuracy: 0.2331\n",
      "Epoch 111/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4994 - accuracy: 0.3090 - val_loss: 0.9083 - val_accuracy: 0.2353\n",
      "Epoch 112/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4931 - accuracy: 0.3079 - val_loss: 0.9088 - val_accuracy: 0.2353\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 832us/step - loss: 0.4874 - accuracy: 0.3084 - val_loss: 0.9116 - val_accuracy: 0.2375\n",
      "Epoch 114/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.4832 - accuracy: 0.3090 - val_loss: 0.9020 - val_accuracy: 0.2353\n",
      "Epoch 115/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4792 - accuracy: 0.3117 - val_loss: 0.9042 - val_accuracy: 0.2288\n",
      "Epoch 116/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.4738 - accuracy: 0.3128 - val_loss: 0.9033 - val_accuracy: 0.2309\n",
      "Epoch 117/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.4673 - accuracy: 0.3205 - val_loss: 0.9101 - val_accuracy: 0.2375\n",
      "Epoch 118/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.4656 - accuracy: 0.3128 - val_loss: 0.9078 - val_accuracy: 0.2331\n",
      "Epoch 119/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.4602 - accuracy: 0.3189 - val_loss: 0.9028 - val_accuracy: 0.2309\n",
      "Epoch 120/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4532 - accuracy: 0.3227 - val_loss: 0.9142 - val_accuracy: 0.2331\n",
      "Epoch 121/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.4513 - accuracy: 0.3194 - val_loss: 0.9070 - val_accuracy: 0.2331\n",
      "Epoch 122/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.4486 - accuracy: 0.3271 - val_loss: 0.9118 - val_accuracy: 0.2309\n",
      "Epoch 123/200\n",
      "107/107 [==============================] - 0s 804us/step - loss: 0.4400 - accuracy: 0.3227 - val_loss: 0.9042 - val_accuracy: 0.2309\n",
      "Epoch 124/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.4367 - accuracy: 0.3260 - val_loss: 0.9111 - val_accuracy: 0.2309\n",
      "Epoch 125/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.4329 - accuracy: 0.3282 - val_loss: 0.9032 - val_accuracy: 0.2331\n",
      "Epoch 126/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.4289 - accuracy: 0.3288 - val_loss: 0.9080 - val_accuracy: 0.2353\n",
      "Epoch 127/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.4240 - accuracy: 0.3255 - val_loss: 0.8973 - val_accuracy: 0.2331\n",
      "Epoch 128/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4197 - accuracy: 0.3299 - val_loss: 0.9033 - val_accuracy: 0.2309\n",
      "Epoch 129/200\n",
      "107/107 [==============================] - 0s 838us/step - loss: 0.4170 - accuracy: 0.3326 - val_loss: 0.8952 - val_accuracy: 0.2331\n",
      "Epoch 130/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.4112 - accuracy: 0.3326 - val_loss: 0.9007 - val_accuracy: 0.2397\n",
      "Epoch 131/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.4076 - accuracy: 0.3337 - val_loss: 0.9069 - val_accuracy: 0.2353\n",
      "Epoch 132/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.4009 - accuracy: 0.3321 - val_loss: 0.9140 - val_accuracy: 0.2266\n",
      "Epoch 133/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.4005 - accuracy: 0.3342 - val_loss: 0.8955 - val_accuracy: 0.2375\n",
      "Epoch 134/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.3990 - accuracy: 0.3342 - val_loss: 0.9067 - val_accuracy: 0.2288\n",
      "Epoch 135/200\n",
      "107/107 [==============================] - 0s 860us/step - loss: 0.3898 - accuracy: 0.3353 - val_loss: 0.8962 - val_accuracy: 0.2331\n",
      "Epoch 136/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.3884 - accuracy: 0.3332 - val_loss: 0.8937 - val_accuracy: 0.2397\n",
      "Epoch 137/200\n",
      "107/107 [==============================] - 0s 879us/step - loss: 0.3824 - accuracy: 0.3375 - val_loss: 0.9012 - val_accuracy: 0.2353\n",
      "Epoch 138/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3781 - accuracy: 0.3370 - val_loss: 0.8915 - val_accuracy: 0.2331\n",
      "Epoch 139/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3814 - accuracy: 0.3359 - val_loss: 0.8949 - val_accuracy: 0.2397\n",
      "Epoch 140/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3692 - accuracy: 0.3375 - val_loss: 0.8996 - val_accuracy: 0.2309\n",
      "Epoch 141/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.3683 - accuracy: 0.3430 - val_loss: 0.8982 - val_accuracy: 0.2353\n",
      "Epoch 142/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.3691 - accuracy: 0.3381 - val_loss: 0.8963 - val_accuracy: 0.2397\n",
      "Epoch 143/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3602 - accuracy: 0.3408 - val_loss: 0.9015 - val_accuracy: 0.2309\n",
      "Epoch 144/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.3568 - accuracy: 0.3447 - val_loss: 0.8972 - val_accuracy: 0.2331\n",
      "Epoch 145/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.3512 - accuracy: 0.3441 - val_loss: 0.9089 - val_accuracy: 0.2331\n",
      "Epoch 146/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.3498 - accuracy: 0.3414 - val_loss: 0.8971 - val_accuracy: 0.2353\n",
      "Epoch 147/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3448 - accuracy: 0.3463 - val_loss: 0.9036 - val_accuracy: 0.2288\n",
      "Epoch 148/200\n",
      "107/107 [==============================] - 0s 860us/step - loss: 0.3420 - accuracy: 0.3469 - val_loss: 0.8873 - val_accuracy: 0.2462\n",
      "Epoch 149/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3394 - accuracy: 0.3469 - val_loss: 0.8946 - val_accuracy: 0.2353\n",
      "Epoch 150/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3369 - accuracy: 0.3502 - val_loss: 0.9056 - val_accuracy: 0.2331\n",
      "Epoch 151/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3324 - accuracy: 0.3447 - val_loss: 0.8906 - val_accuracy: 0.2418\n",
      "Epoch 152/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3281 - accuracy: 0.3474 - val_loss: 0.8972 - val_accuracy: 0.2353\n",
      "Epoch 153/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.3247 - accuracy: 0.3535 - val_loss: 0.9010 - val_accuracy: 0.2375\n",
      "Epoch 154/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3215 - accuracy: 0.3513 - val_loss: 0.8956 - val_accuracy: 0.2331\n",
      "Epoch 155/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3178 - accuracy: 0.3485 - val_loss: 0.9072 - val_accuracy: 0.2353\n",
      "Epoch 156/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.3143 - accuracy: 0.3535 - val_loss: 0.8990 - val_accuracy: 0.2309\n",
      "Epoch 157/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.3118 - accuracy: 0.3524 - val_loss: 0.9002 - val_accuracy: 0.2375\n",
      "Epoch 158/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.3072 - accuracy: 0.3568 - val_loss: 0.8951 - val_accuracy: 0.2418\n",
      "Epoch 159/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.3035 - accuracy: 0.3634 - val_loss: 0.8952 - val_accuracy: 0.2353\n",
      "Epoch 160/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.2996 - accuracy: 0.3595 - val_loss: 0.8922 - val_accuracy: 0.2375\n",
      "Epoch 161/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.2969 - accuracy: 0.3606 - val_loss: 0.8972 - val_accuracy: 0.2331\n",
      "Epoch 162/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2982 - accuracy: 0.3584 - val_loss: 0.9032 - val_accuracy: 0.2309\n",
      "Epoch 163/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2925 - accuracy: 0.3617 - val_loss: 0.8948 - val_accuracy: 0.2397\n",
      "Epoch 164/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2869 - accuracy: 0.3667 - val_loss: 0.8957 - val_accuracy: 0.2418\n",
      "Epoch 165/200\n",
      "107/107 [==============================] - 0s 916us/step - loss: 0.2843 - accuracy: 0.3617 - val_loss: 0.8980 - val_accuracy: 0.2375\n",
      "Epoch 166/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2830 - accuracy: 0.3656 - val_loss: 0.8994 - val_accuracy: 0.2375\n",
      "Epoch 167/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.2805 - accuracy: 0.3661 - val_loss: 0.9017 - val_accuracy: 0.2418\n",
      "Epoch 168/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2759 - accuracy: 0.3656 - val_loss: 0.8927 - val_accuracy: 0.2397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2724 - accuracy: 0.3711 - val_loss: 0.9028 - val_accuracy: 0.2462\n",
      "Epoch 170/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2703 - accuracy: 0.3683 - val_loss: 0.8932 - val_accuracy: 0.2462\n",
      "Epoch 171/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2663 - accuracy: 0.3694 - val_loss: 0.9070 - val_accuracy: 0.2309\n",
      "Epoch 172/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2648 - accuracy: 0.3705 - val_loss: 0.8964 - val_accuracy: 0.2375\n",
      "Epoch 173/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.2604 - accuracy: 0.3716 - val_loss: 0.8969 - val_accuracy: 0.2418\n",
      "Epoch 174/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.2609 - accuracy: 0.3755 - val_loss: 0.8995 - val_accuracy: 0.2375\n",
      "Epoch 175/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2562 - accuracy: 0.3716 - val_loss: 0.9001 - val_accuracy: 0.2375\n",
      "Epoch 176/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2507 - accuracy: 0.3766 - val_loss: 0.8906 - val_accuracy: 0.2331\n",
      "Epoch 177/200\n",
      "107/107 [==============================] - 0s 879us/step - loss: 0.2533 - accuracy: 0.3722 - val_loss: 0.8902 - val_accuracy: 0.2331\n",
      "Epoch 178/200\n",
      "107/107 [==============================] - 0s 953us/step - loss: 0.2468 - accuracy: 0.3755 - val_loss: 0.9045 - val_accuracy: 0.2418\n",
      "Epoch 179/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2464 - accuracy: 0.3804 - val_loss: 0.8866 - val_accuracy: 0.2418\n",
      "Epoch 180/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2403 - accuracy: 0.3804 - val_loss: 0.9022 - val_accuracy: 0.2484\n",
      "Epoch 181/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2404 - accuracy: 0.3832 - val_loss: 0.8931 - val_accuracy: 0.2440\n",
      "Epoch 182/200\n",
      "107/107 [==============================] - 0s 888us/step - loss: 0.2362 - accuracy: 0.3815 - val_loss: 0.8935 - val_accuracy: 0.2484\n",
      "Epoch 183/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2347 - accuracy: 0.3799 - val_loss: 0.9068 - val_accuracy: 0.2440\n",
      "Epoch 184/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2321 - accuracy: 0.3821 - val_loss: 0.8883 - val_accuracy: 0.2462\n",
      "Epoch 185/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.2286 - accuracy: 0.3848 - val_loss: 0.8945 - val_accuracy: 0.2375\n",
      "Epoch 186/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2272 - accuracy: 0.3865 - val_loss: 0.8929 - val_accuracy: 0.2462\n",
      "Epoch 187/200\n",
      "107/107 [==============================] - 0s 865us/step - loss: 0.2241 - accuracy: 0.3843 - val_loss: 0.8853 - val_accuracy: 0.2462\n",
      "Epoch 188/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2235 - accuracy: 0.3837 - val_loss: 0.9034 - val_accuracy: 0.2462\n",
      "Epoch 189/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.2200 - accuracy: 0.3859 - val_loss: 0.9019 - val_accuracy: 0.2418\n",
      "Epoch 190/200\n",
      "107/107 [==============================] - 0s 850us/step - loss: 0.2193 - accuracy: 0.3832 - val_loss: 0.9063 - val_accuracy: 0.2375\n",
      "Epoch 191/200\n",
      "107/107 [==============================] - 0s 822us/step - loss: 0.2140 - accuracy: 0.3903 - val_loss: 0.8923 - val_accuracy: 0.2309\n",
      "Epoch 192/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2121 - accuracy: 0.3920 - val_loss: 0.8902 - val_accuracy: 0.2549\n",
      "Epoch 193/200\n",
      "107/107 [==============================] - 0s 831us/step - loss: 0.2105 - accuracy: 0.3859 - val_loss: 0.8818 - val_accuracy: 0.2505\n",
      "Epoch 194/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.2078 - accuracy: 0.3903 - val_loss: 0.8861 - val_accuracy: 0.2505\n",
      "Epoch 195/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2042 - accuracy: 0.3942 - val_loss: 0.8858 - val_accuracy: 0.2484\n",
      "Epoch 196/200\n",
      "107/107 [==============================] - 0s 832us/step - loss: 0.2043 - accuracy: 0.3898 - val_loss: 0.8934 - val_accuracy: 0.2440\n",
      "Epoch 197/200\n",
      "107/107 [==============================] - 0s 813us/step - loss: 0.2023 - accuracy: 0.3898 - val_loss: 0.8923 - val_accuracy: 0.2418\n",
      "Epoch 198/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.1987 - accuracy: 0.3909 - val_loss: 0.8990 - val_accuracy: 0.2462\n",
      "Epoch 199/200\n",
      "107/107 [==============================] - 0s 869us/step - loss: 0.1976 - accuracy: 0.3942 - val_loss: 0.8920 - val_accuracy: 0.2505\n",
      "Epoch 200/200\n",
      "107/107 [==============================] - 0s 841us/step - loss: 0.1933 - accuracy: 0.3931 - val_loss: 0.8864 - val_accuracy: 0.2484\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "hist = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=8,\n",
    "          epochs=200,\n",
    "          validation_split=0.2).history\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "F7CLju35P3oK",
    "outputId": "63ab40e2-0823-4a49-c4e4-f41dbf5d99db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsz6McDxix8Y"
   },
   "outputs": [],
   "source": [
    "#We are ready for inference. \n",
    "#(kopi o <pad> <pad> <pad>)\t---------> ($START black coffee with sugar END$)\n",
    "  ##Encoder(kopi o <pad> <pad> <pad>) = (h0,c0)\n",
    "    ##(h0,c0) +  $START ----decoder-----> (black,  (h1,c1)) \n",
    "    ##(h1,c1)\t+  black -----decoder---->  (coffee, (h2,c2))\n",
    "    ##(h2,c2)\t+  coffee ----decoder-----> (with,   (h3,c3))\n",
    "    ##(h3,c3)\t+  with ------decoder--->   (sugar,  (h4,c4))\n",
    "    ##(h4,c4)\t+  sugar -----decoder---->  (END$,   (h5,c5))\n",
    "\n",
    "\n",
    "#To decode a test sentence, we will repeatedly:\n",
    "#1) Encode the input sentence and retrieve the initial state (encoder_states = [state_h, state_c])\n",
    "        ##(kopi o)--->encoder_states = [state_h, state_c]\n",
    "#2) Run one step of the decoder ([state_h, state_c] + START_ -----> black)\n",
    "    #initial state(encoder_states = [state_h, state_c]) and a \"START_\" token as input. \n",
    "    #The output will be the next Target_Word (may or maynot be \"black\").\n",
    "#3) Append the Target_Word with previous input (\"START_ Target_Word\")  and REPEAT (utill \"_END\" predicted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "lCk7N-le65Lp",
    "outputId": "50cdcdb7-f04d-4780-a9a1-a844d588c040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 63)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 32), (None, 32),  12288     \n",
      "=================================================================\n",
      "Total params: 12,288\n",
      "Trainable params: 12,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 109)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 32), ( 18176       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 109)    3597        lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 21,773\n",
      "Trainable params: 21,773\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define encode_model seperatly as training stage \n",
    "#(kopi o)--->encoder_states = [state_h, state_c]\n",
    "encoder_model = Model(encoder_inputs, encoder_states) #reusing the [encoder_inputs,encoder_states]\n",
    "encoder_model.summary()\n",
    "\n",
    "#define decoder_model seperatly as training stages\n",
    "#[_h, _c] for decoder LSTM\n",
    "decoder_state_input_h = Input(shape=(hidden_dim,))\n",
    "decoder_state_input_c = Input(shape=(hidden_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# [decoder_input, h_t0, c_t0] for decoder LSTM\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# predict [h_t1, c_t1]\n",
    "decoder_states = [state_h, state_c]\n",
    "# predict [target_Seq_t1]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SUHvsHC67mN"
   },
   "outputs": [],
   "source": [
    " ##Encoder(kopi o <pad> <pad> <pad>) = (h0,c0)\n",
    "    ##(h0,c0) +  $START ----decoder-----> (black,  (h1,c1)) \n",
    "    ##(h1,c1)\t+  black -----decoder---->  (coffee, (h2,c2))\n",
    "    ##(h2,c2)\t+  coffee ----decoder-----> (with,   (h3,c3))\n",
    "    ##(h3,c3)\t+  with ------decoder--->   (sugar,  (h4,c4))\n",
    "    ##(h4,c4)\t+  sugar -----decoder---->  (END$,   (h5,c5))\n",
    "\n",
    "def decode_sequence(input_seq,num_decoder_tokens,encoder_model,decoder_model,vocab_B,max_decoder_seq_length,maxlen_A,vocab_size_A):\n",
    "\n",
    "    if len(input_seq)==0:\n",
    "        return [vocab_B['end$']]\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    ##Encoder(kopi o <pad> <pad> <pad>) = (h0,c0)\n",
    "\n",
    "    encoder_input_text = np.zeros((1, maxlen_A, vocab_size_A), dtype='float32')\n",
    "    for t, word_id in enumerate(input_seq):\n",
    "        encoder_input_text[0, t, word_id] = 1.\n",
    "\n",
    "    states_value = encoder_model.predict(encoder_input_text)\n",
    "\n",
    "    # Generate empty target sequence of word_token.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "\n",
    "    # Initialize with $start\n",
    "    target_seq[0, 0, vocab_B['$start']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1 (greedy decoding)).\n",
    "    stop_condition = False\n",
    "    decoded_word_index = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        ##(h0,c0) +  $START ----decoder-----> (???,  (h1,c1)) \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Predict the best token (black)\n",
    "        predict_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        decoded_word_index.append(predict_token_index)\n",
    "\n",
    "        # Exit condition: either hit max length # or find stop character.\n",
    "        if (predict_token_index == vocab_B['end$'] or len(decoded_word_index) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        ##(h1,c1)\t+  black -----decoder---->  (???, (h2,c2))\n",
    "\n",
    "        # Update the target sequence to the predict word_token\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, predict_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LHsBrNmnAjN_",
    "outputId": "cd140bfb-0500-4685-b81c-b8c1323810eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5]\n",
      "[5, 3, 9, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "#Try with the first row\n",
    "\n",
    "print(seqA[0])\n",
    "r = decode_sequence(seqA[0],vocab_size_B,encoder_model,decoder_model,word_index_B,maxlen_B,maxlen_A,vocab_size_A)\n",
    "print (r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h47IfppdVbCt",
    "outputId": "4bb80b9d-3d99-4091-a849-c96f7b06eb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kopi', 'kosong']\n",
      "['coffee', 'with', 'condensed', 'milk', 'end$']\n"
     ]
    }
   ],
   "source": [
    "# Creating a reverse dictionary\n",
    "\n",
    "reverse_word_map_A = dict(map(reversed, tokenizer_A.word_index.items()))\n",
    "reverse_word_map_B = dict(map(reversed, tokenizer_B.word_index.items()))\n",
    "\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def indexSeq_to_text_A(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map_A.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "\n",
    "def indexSeq_to_text_B(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map_B.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "\n",
    "print(indexSeq_to_text_A(seqA[0]))\n",
    "print(indexSeq_to_text_B(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03e1PEIfj2AM"
   },
   "outputs": [],
   "source": [
    "#Translater for a list of seqA to seqB     \n",
    "def testSeq2Sq(listOfSeqA):\n",
    "    listOfSeqB=[]\n",
    "    token_seqA = tokenizer_A.texts_to_sequences(listOfSeqA)\n",
    "    \n",
    "    for a in token_seqA:\n",
    "        r = decode_sequence(a,vocab_size_B,encoder_model,decoder_model,word_index_B,maxlen_B,maxlen_A,vocab_size_A)\n",
    "        tokens_b = indexSeq_to_text_B(r)\n",
    "        sentB = ' '.join(tokens_b)\n",
    "        listOfSeqB.append(sentB)\n",
    "        \n",
    "    return listOfSeqB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "PeDvkEVFxdVs",
    "outputId": "1f699ede-6b26-4a6e-f665-36b5958322ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqA</th>\n",
       "      <th>SeqB</th>\n",
       "      <th>Translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kopi gau peng</td>\n",
       "      <td>$START strong iced coffee with condensed milk ...</td>\n",
       "      <td>iced black coffee with sugar end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>teh c</td>\n",
       "      <td>$START tea with evaporated milk and sugar END$</td>\n",
       "      <td>tea with evaporated milk and sugar end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>diao yu</td>\n",
       "      <td>$START chinese tea END$</td>\n",
       "      <td>chinese tea end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>kopi gau</td>\n",
       "      <td>$START strong brew of coffee with condensed mi...</td>\n",
       "      <td>strong coffee with condensed milk end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>kopi o gau siew dai</td>\n",
       "      <td>$START hot black coffee with more coffee powde...</td>\n",
       "      <td>hot black coffee with more coffee powder and m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SeqA  ...                                         Translated\n",
       "13         kopi gau peng  ...                  iced black coffee with sugar end$\n",
       "159                teh c  ...            tea with evaporated milk and sugar end$\n",
       "69               diao yu  ...                                   chinese tea end$\n",
       "148             kopi gau  ...             strong coffee with condensed milk end$\n",
       "44   kopi o gau siew dai  ...  hot black coffee with more coffee powder and m...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with fresh data\n",
    "\n",
    "decode_testSeqB = testSeq2Sq(testlines.SeqA)\n",
    "testlines['Translated'] = decode_testSeqB\n",
    "testlines.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "PCTXYqFZkGNK",
    "outputId": "0f1242cb-636f-41c9-8ae2-a4760e6baef0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqA</th>\n",
       "      <th>SeqB</th>\n",
       "      <th>Translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kopi kosong</td>\n",
       "      <td>$START black coffee without sugar or milk END$</td>\n",
       "      <td>coffee with condensed milk but sugar end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kopi gau</td>\n",
       "      <td>$START strong coffee with condensed milk END$</td>\n",
       "      <td>strong coffee with condensed milk end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>teh o</td>\n",
       "      <td>$START tea with sugar only END$</td>\n",
       "      <td>tea with sugar only end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kopi c</td>\n",
       "      <td>$START black coffee with evaporated milk END$</td>\n",
       "      <td>hot coffee with evaporated milk and sugar end$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kopi gau ga dai</td>\n",
       "      <td>$START hot coffee with condensed milk and more...</td>\n",
       "      <td>hot coffee with condensed milk and more coffee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SeqA  ...                                         Translated\n",
       "3        kopi kosong  ...          coffee with condensed milk but sugar end$\n",
       "9           kopi gau  ...             strong coffee with condensed milk end$\n",
       "161            teh o  ...                           tea with sugar only end$\n",
       "2             kopi c  ...     hot coffee with evaporated milk and sugar end$\n",
       "25   kopi gau ga dai  ...  hot coffee with condensed milk and more coffee...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with known training data\n",
    "sample_train=lines[:10]\n",
    "decode_sample_train = testSeq2Sq(sample_train.SeqA)\n",
    "sample_train['Translated'] = decode_sample_train\n",
    "sample_train.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq_LSTM_woeb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
