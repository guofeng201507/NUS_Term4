{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IM_he-xd2CC"
   },
   "source": [
    "# Text classification with Transformer\n",
    "\n",
    "**Author:** [Apoorv Nandan](https://twitter.com/NandanApoorv)<br>\n",
    "**Date created:** 2020/05/10<br>\n",
    "**Last modified:** 2020/05/10<br>\n",
    "**Description:** Implement a Transformer block as a Keras layer and use it for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgPaxMrXd2CD"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1divninpd2CE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1E2F1dXd2CH"
   },
   "source": [
    "## Implement multi head self attention as a Keras layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-A203QOrd2CH"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2qG2KUbd2CK"
   },
   "source": [
    "## Implement a Transformer block as a layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFk57YT2d2CL"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AA6GfXd3d2CN"
   },
   "source": [
    "## Implement embedding layer\n",
    "\n",
    "Two seperate embedding layers, one for tokens, one for token index (positions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8nRWsoHd2CO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dO1wA39Ld2CQ"
   },
   "source": [
    "## Download and prepare dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LW7NEJCd2CR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbZGi3q2d2CT"
   },
   "source": [
    "## Create classifier model using transformer layer\n",
    "\n",
    "Transformer layer outputs one vector for each time step of our input sequence.\n",
    "Here, we take the mean across all time steps and\n",
    "use a feed forward network on top of it to classify text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e_rlTEad2CT"
   },
   "outputs": [],
   "source": [
    "\n",
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-EF0Ctpd2CW"
   },
   "source": [
    "## Train and Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAK5ou2dd2CX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/50\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.3843 - accuracy: 0.8162 - val_loss: 0.2913 - val_accuracy: 0.8771\n",
      "Epoch 2/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.2010 - accuracy: 0.9229 - val_loss: 0.3475 - val_accuracy: 0.8537\n",
      "Epoch 3/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.1334 - accuracy: 0.9526 - val_loss: 0.3940 - val_accuracy: 0.8613\n",
      "Epoch 4/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0914 - accuracy: 0.9672 - val_loss: 0.4143 - val_accuracy: 0.8547\n",
      "Epoch 5/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.5652 - val_accuracy: 0.8491\n",
      "Epoch 6/50\n",
      "25000/25000 [==============================] - 34s 1ms/sample - loss: 0.0436 - accuracy: 0.9846 - val_loss: 0.7308 - val_accuracy: 0.8446\n",
      "Epoch 7/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.8631 - val_accuracy: 0.8402\n",
      "Epoch 8/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.8246 - val_accuracy: 0.8416\n",
      "Epoch 9/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.8373 - val_accuracy: 0.8412\n",
      "Epoch 10/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.8276 - val_accuracy: 0.8403\n",
      "Epoch 11/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.8941 - val_accuracy: 0.8376\n",
      "Epoch 12/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.1050 - val_accuracy: 0.8314\n",
      "Epoch 13/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0082 - accuracy: 0.9969 - val_loss: 1.1007 - val_accuracy: 0.8213\n",
      "Epoch 14/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.0258 - val_accuracy: 0.8362\n",
      "Epoch 15/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.4068 - val_accuracy: 0.8189\n",
      "Epoch 16/50\n",
      "25000/25000 [==============================] - 34s 1ms/sample - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.2922 - val_accuracy: 0.8342\n",
      "Epoch 17/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.2586 - val_accuracy: 0.8314\n",
      "Epoch 18/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.2284 - val_accuracy: 0.8299\n",
      "Epoch 19/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 1.3390 - val_accuracy: 0.8189\n",
      "Epoch 20/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0073 - accuracy: 0.9972 - val_loss: 1.0413 - val_accuracy: 0.8336\n",
      "Epoch 21/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 1.3829 - val_accuracy: 0.8271\n",
      "Epoch 22/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0046 - accuracy: 0.9984 - val_loss: 1.7894 - val_accuracy: 0.8284\n",
      "Epoch 23/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0047 - accuracy: 0.9983 - val_loss: 1.4521 - val_accuracy: 0.8268\n",
      "Epoch 24/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0708 - val_accuracy: 0.8190\n",
      "Epoch 25/50\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.3504 - val_accuracy: 0.8319\n",
      "Epoch 26/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.6548 - val_accuracy: 0.8246\n",
      "Epoch 27/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.5727 - val_accuracy: 0.8288\n",
      "Epoch 28/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.1033 - val_accuracy: 0.8127\n",
      "Epoch 29/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0041 - accuracy: 0.9985 - val_loss: 1.7903 - val_accuracy: 0.8312\n",
      "Epoch 30/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 1.6251 - val_accuracy: 0.8248\n",
      "Epoch 31/50\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.9055 - val_accuracy: 0.8213\n",
      "Epoch 32/50\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.1333 - val_accuracy: 0.8243\n",
      "Epoch 33/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.2785 - val_accuracy: 0.8242\n",
      "Epoch 34/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 1.9075 - val_accuracy: 0.8238\n",
      "Epoch 35/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.9005 - val_accuracy: 0.8185\n",
      "Epoch 36/50\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.7798 - val_accuracy: 0.8183\n",
      "Epoch 37/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.8944 - val_accuracy: 0.8205\n",
      "Epoch 38/50\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.7338 - val_accuracy: 0.8142\n",
      "Epoch 39/50\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 1.5628 - val_accuracy: 0.8229\n",
      "Epoch 40/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.0997 - val_accuracy: 0.8255\n",
      "Epoch 41/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.0970 - val_accuracy: 0.8234\n",
      "Epoch 42/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.7411 - val_accuracy: 0.8240\n",
      "Epoch 43/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 1.2901e-04 - accuracy: 1.0000 - val_loss: 2.1041 - val_accuracy: 0.8200\n",
      "Epoch 44/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 5.5682e-06 - accuracy: 1.0000 - val_loss: 2.1922 - val_accuracy: 0.8193\n",
      "Epoch 45/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 6.2462e-06 - accuracy: 1.0000 - val_loss: 2.2684 - val_accuracy: 0.8199\n",
      "Epoch 46/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 2.0123e-06 - accuracy: 1.0000 - val_loss: 2.3513 - val_accuracy: 0.8196\n",
      "Epoch 47/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 2.0367e-06 - accuracy: 1.0000 - val_loss: 2.4437 - val_accuracy: 0.8195\n",
      "Epoch 48/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 9.5599e-07 - accuracy: 1.0000 - val_loss: 2.5177 - val_accuracy: 0.8193\n",
      "Epoch 49/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 9.9363e-07 - accuracy: 1.0000 - val_loss: 2.6221 - val_accuracy: 0.8192\n",
      "Epoch 50/50\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 8.3452e-07 - accuracy: 1.0000 - val_loss: 2.7476 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=50, validation_data=(x_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of text_classification_with_transformer",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
